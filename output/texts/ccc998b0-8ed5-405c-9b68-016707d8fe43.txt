Recurrent neural networks, long short-term memory [12] and gated recurrent [7] neural networks in particular, have been Ô¨Årmly established as state of the art approaches in sequence modeling and transduction problems such as language modeling and machine translation [29, 2, 5]. Numerous efforts have since continued to push the boundaries of recurrent language models and encoder-decoder architectures [31, 21, 13].